---
title: MIT 6.041 Probabilistic Systems Analysis and Applied Probability - 2.Conditioning and Bayes' Rule
layout: post
categories: [Probability, Math, MIT 6.041 Probabilistic Systems Analysis and Applied Probability]
image: /assets/img/MIT6.041/cover.jpg
description: "MIT 6.041 2.Conditioning and Bayes' Rule"
customexcerpt: "Notes for MIT opencourse MIT 6.041 Probabilistic Systems Analysis and Applied Probability"
---

* 
{:toc}




## 2.Conditioning and Bayes' Rule 条件概率和贝叶斯定理

#### Review of last class

**可加性(Additivity)公理**能否运用于**不可数无限 uncountable infinite**个集合呢？

我们来看这个例子：

一个单位正方形的样本空间 $\Omega = \\{(x,y)\|0\leq x,y\leq 1,\ x,y\in \mathbb{R}\\}$

我们知道$\Omega$是由所有满足条件的点并起来的，即

$$
\Omega = \bigcup_{0\leq x,y\leq 1} \{(x,y)\}
$$

那么，$\Omega$的概率似乎满足

$$
1 = P(\Omega) = P(\bigcup_{0\leq x,y\leq 1} \{(x,y)\}) = \sum P(\{(x,y)\}) = \sum 0 = 0
$$

因为一个点的概率是0

于是我们证明了**1=0**，哦，多么美丽的结果阿！

<img src="\assets\img\MIT6.041\2\1.jpg" alt="1" style="zoom: 25%;" />

这样的证明肯定是有问题的，问题就出在对于**不可数无限个 uncountable infinite**集合的交（不可数交）运用了**可加性(Additivity)公理**

事实上可加性公理只能运用于**有限**个集合的交，或是有限序列（即**可数 countable**）个集合的交，这是需要注意的

同时这个例子也可以说明，**对于连续的样本空间，概率为0不代表不可能发生；同样的，概率为1不代表一定发生（思考飞镖不落在(0,0)这点的概率）**



#### Conditional Probability 条件概率

条件概率指的是一个事件在另一个事件已经发生的条件下的概率

$P(A\|B)$ 代表事件B发生时，事件A的概率

假设$P(B) \neq 0$,

$$
P(A\|B) = \frac{P(A\cap B)}{P(B)}
$$

如果$P(B) = 0$，$P(A\|B)$是未定义的

这很好理解，假设A的概率是5/6，B的概率是1/2，则$A\cap B$的概率是1/3

![2](\assets\img\MIT6.041\2\2.png)

如果B已经发生了，那么A仍然发生的部分就是$A\cap B$,而这部分的概率在整个事件B中的概率就是

$$
\frac{P(A\cap B)}{P(B)} = \frac{1/3}{1/2} = 2/3
$$

同样，我们也可以这样理解公式：

$$
P(A\cap B) = P(B)P(A\|B)
$$

AB同时发生的概率即为B发生的概率乘一个A在B中的占比，$P(A\|B)$就是比例因子



条件概率和普通的概率没什么大的区别，描述的无非就是一个事件发生的新的状态下的普通概率

从这个角度出发，以下公式就是显然的:

若$A\cap B = \varnothing$,

$$
P(A\cup B \|C) = P(A\|C)+P(B\|C)
$$

C事件发生后，AB之间的关系该怎么来就怎么来

当然，通过条件概率的定义也可以轻易证明，这里略



条件概率反映的是某一事件（假设是B）发生时另一件事（假设是A）发生的概率，若忽略了事件B发生的概率，单从条件概率来看A单独发生的概率，是容易产生错觉的。举一个例子，若B发生的概率是1%，$A\cap B$发生的概率是0.99%，那么在事件B的条件下A的概率就是99%，看似很高，但是事实上从整体来看，和A发生的概率没有太多联系。A的概率可以很高，也可以很低。这里需要注意。



#### Multiplication rule  乘法法则

$$
P(A\cap B\cap C)=P(A)P(B\|A)P(C\|A\cap B)
$$

更一般的版本,对于至多是可数个的集合

$$
P(A_1\cap\cdots\cap A_n) = P(A_1)P(A_2\|A_1)P(A_3\|A_1\cap A_2)\cdots=\prod_{k=1}^n P(A_k\|\bigcap_{j=1}^{k-1}A_j)
$$

这个式子也不难理解：前k项是$A_1-A_k$事件同时发生的概率，乘上的第k+1项即在$A_1-A_k$同时发生的条件下$A_{k+1}$的条件概率

决策树也能够帮助理解：

<img src="\assets\img\MIT6.041\2\3.png" alt="3" style="zoom: 67%;" />



#### Total probability theorem 全概率定理

> 若$A_1,\cdots,A_n$两两互斥，即$A_i \cap A_j = \varnothing,\ i\neq j,\ i,j = 1,2,\cdots,n$
>
> 且$A_1\cap\cdots\cap A_n = \Omega$
>
> 则称$A_1,\cdots,A_n$为$\Omega$的一个**划分 Partition**

若$A_1,\cdots,A_n$（此处n可以无穷大，即可数无穷的序列）为样本空间$\Omega$的一个划分,则

$$
P(B) = P(A_1)P(B\|A_1)+\cdots+P(A_n)P(B\|A_n) = \sum_{i=1}^n P(A_i)P(B\|A_i)
$$

![4](\assets\img\MIT6.041\2\4.png)

通过图我们可以清晰地认识到，B发生的概率就等于n块$A_n\cap B$发生的概率之和，而$A_n\cap B$就是在An的条件下B发生的概率，即条件概率，乘以An发生的概率。从另一个角度思考，$P(B\|A_n)$代表着B在An中的占比，为了得出总的B，我们只需要把所有B在An中占有的部分求和即可。

这个公式也可以理解为B发生的概率是所有可能场景(An)下B事件发生的权重平均



#### Bayes's Rule 贝叶斯定理

我们知道条件概率满足的关系：

$$
P(A_i\|B) = \frac{P(A_i\cap B)}{P(B)}
$$

同时我们也知道B发生的概率为所有B在An中占有的部分之和

$$
P(B) = \sum_{j=1}^n P(A_j)P(B\|A_j)
$$

注意到$P(A_i\cap B) = P(B)P(A_i\|B) = P(A_i)P(B\|A_i)$

联立三个公式，可得:

$$
P(A_i\|B) = \frac{P(A_i\cap B)}{P(B)} \\= \frac{P(A_i)P(B\|A_i)}{P(B)}\\=\frac{P(A_i)P(B\|A_i)}{\sum_{j=1}^n P(A_j)P(B\|A_j)}
$$

即**贝叶斯公式 Bayes's Rule**

该公式的意义在于，**通过结果的概率，寻找原因的概率**

$A_i$导致了B，我们知道了所有情境下B发生的概率

于是通过贝叶斯公式，我们就可以得知在B发生的情境下，"原因事件"$A_i$发生的概率